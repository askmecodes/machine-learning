# Machine Learning

## Linear Regression

- What is linear and non linear regression?
- How do you calculate simple linear regression?
- What is linear and non linear regression?
- What is the difference between regression and correlation?
- What are regression coefficients? How do you determine them analytically?
- How do you obtain closed form solution in linear regression?
- What is OLS regression model?
- What is difference between linear and logistic regression?
- What is a regression curve?
- What is the difference between simple linear regression and multiple linear regression?
- How do you tell if a regression model is a good fit?
- What is a good R squared value?
- What does R Squared mean?
- What is the difference between linear and polynomial regression?
- What does the Optimizer usually do in gradient descent in linear regression?
- How do you set up optimization problem and solve it in case of linear regression?
- What is difference between closed form solution and gradient descent solution?
- What are the issues with Gradient Descent?
- Explain Bias Variance in Linear Regression. What does it mean by bias-variance trade off?
- Derive MSE in terms of Bias and Variance of estimator over different realization of training data and one set of test data.
- Is linear regression a neural network?
- Is linear regression always convex?
- Which algorithm is used for regression?
- What is Regularization in Linear Regression?
- Why does regularization reduce Overfitting?
- What is l1 and l2 regularization?
- What is ridge regression used for?
- What is closed form solution of Ridge Regression?
- What are upper and lower limit of $\lambda$ in Ridge regression?
- What is cost function in Ridge regression? How do you define optimization problem?
- How do you apply gradient descent in case of Ridge Regression?
- What happens to the regression coefficients (weights) when you increase $\alpha$ in Ridge regression?
- Why is it called ridge regression?












